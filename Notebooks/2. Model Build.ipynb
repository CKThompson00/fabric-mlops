{"cells":[{"cell_type":"markdown","id":"388d70f5-6482-4323-924f-806cba7ebd5f","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Model Build Notebook\n","This notebook will walk through all steps to build a model.  This notebook should be scheduled on a frequent basis and aligned with the Validation notebook.\n","\n","You will need to update the cells in this notebook related to your model build, metrics, etc.  You will also need to updae any imports related to the mode building process.  The sample provided demonstrated XGBoost with the iris dataset.\n","\n"]},{"cell_type":"markdown","id":"86bd678f-ad58-4ac8-a584-a15b39fd409b","metadata":{"jupyter":{"magics_cell_name":"magics-cell-markdown","magics_signature":"27ac753c3c60167f65c4d05fa7809cd85f1f0273d5b842aca4f65a01"}},"source":["-----------------------------------\n","## Step 1\n","#### Install required packages for the model build process.\n"]},{"cell_type":"code","execution_count":null,"id":"bdf8efb6-1587-4f9c-a74c-e86569b5592f","metadata":{"editable":true,"run_control":{"frozen":false}},"outputs":[],"source":["import time\n","import pandas as pd\n","import xgboost as xgb\n","from pyspark.ml.feature import StringIndexer\n","import sklearn\n","import mlflow\n","from mlflow.entities import ViewType\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_score\n"]},{"cell_type":"markdown","id":"ffbca19c-732d-4d03-94a9-819e48dc718d","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["-----------------------------------\n","## Step 2\n","### Start an Experiment and Register with MLFlow"]},{"cell_type":"code","execution_count":null,"id":"dbcde4fa-cbdc-4a4d-adc3-ab4be178157f","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Get the current notebook name as the key to look up other config\n","NOTEBOOK_NAME = mssparkutils.runtime.context['currentNotebookName']\n","#**********************************************\n","\n","sql_query = \"SELECT * FROM MLOpsConfig WHERE notebook ='{}'\".format(NOTEBOOK_NAME)\n","df = spark.sql(sql_query)\n","df2 =  df.toPandas()\n","EXPERIMENT_NAME = df2.loc[:,\"experiment\"].values[0]\n","\n","mlflow.set_experiment(EXPERIMENT_NAME)\n","mlflow.autolog()\n"]},{"cell_type":"markdown","id":"8a1702ed-7324-4054-a471-3c99c9315860","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["-----------------------------------\n","## Step 3\n","### Read Dataset to be for Model build."]},{"cell_type":"code","execution_count":null,"id":"9fc64021-bace-4023-b154-922cefe6cf49","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["df = spark.read.format(\"parquet\").option(\"header\",\"true\").load(\"Files/iris/transformed_iris.parquet\")"]},{"cell_type":"markdown","id":"5ec19f58-6e67-4e35-b808-56e4da92b95b","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["-----------------------------------\n","## Step 4 \n","### Data splitting/Create xgb DMatrix"]},{"cell_type":"code","execution_count":null,"id":"01ed6d7e-3f1b-494b-82ed-a4687bd7cccc","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Split to train/test\n","df = df.toPandas()\n","training_df, test_df = train_test_split(df)\n","\n","# Create DMatrix\n","dtrain = xgb.DMatrix(training_df[[\"sepal length\",\"sepal width\", \"petal length\", \"petal width\"]], label=training_df[\"variety_index\"])\n"]},{"cell_type":"markdown","id":"f194a0c9-5790-46f6-9d18-aafa571cb9a4","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["-----------------------------------\n","## Step 5\n","### Train Model"]},{"cell_type":"code","execution_count":null,"id":"e1b0dc59-66d0-4fda-b117-88e86b3519c2","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["mlflow.autolog(exclusive=False)\n","\n","# Run Name based on date/time\n","run_name = time.strftime(\"%Y%m%d-%H%M%S\")\n","\n","# Start MLFlow with the Run Name\n","with mlflow.start_run(run_name=run_name):\n","    \n","    # Write any custom metrics to the run within MLFlow \n","    param = {'max_depth': 3, 'eta': 1, 'silent': 1, 'objective': 'multi:softmax'}\n","    param['nthread'] = 4\n","    param['eval_metric'] = 'auc'\n","    param['num_class'] = 6\n","    mlflow.log_params(param)\n","\n","    # Train\n","    num_round = 10\n","    bst = xgb.train(param, dtrain, num_round)\n","    dtest = xgb.DMatrix(test_df[[\"sepal length\",\"sepal width\", \"petal length\", \"petal width\"]])\n","    ypred = bst.predict(dtest)\n","\n","    # Score and write metrics to MLFlow.  We will use these to consider whether or not to promote this to the next environment.\n","    pre_score = precision_score(test_df[\"variety_index\"],ypred, average='micro')\n","    print(\"xgb_pre_score:\",pre_score)\n","    mlflow.log_metric('xgb_pre_score', pre_score)\n"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"e67c66fd-41fd-49be-a121-fe5b8c7db9c5","default_lakehouse_name":"mylakehouse","default_lakehouse_workspace_id":"a6901f53-b419-4f03-8610-69286a189ce5"}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"notebook_environment":{},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{},"enableDebugMode":false}},"synapse_widget":{"state":{},"version":"0.1"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
